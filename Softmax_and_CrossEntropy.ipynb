{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef283b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Softmax converts raw model outputs (logits) into probabilities that sum to 1.\n",
    "# Cross Entropy Loss measures the difference between predicted probabilities and true class labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c14e9706",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7ce2ac8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.84008305 0.11369288 0.04622407]\n"
     ]
    }
   ],
   "source": [
    "# Manual calculation of softmax function\n",
    "\n",
    "def manual_softmax(x):\n",
    "    return  np.exp(x)/np.sum(np.exp(x),axis=0)\n",
    "\n",
    "x = np.array([3.0,1.0,0.1])\n",
    "outputs = manual_softmax(x)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe8c4303",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8401, 0.1137, 0.0462], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Using Pytorch softmax function\n",
    "x = np.array([3.0,1.0,0.1])\n",
    "x = torch.tensor(x)\n",
    "outputs = torch.softmax(x,dim=0)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "05ab5344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 0.3567\n",
      "Loss 2: 2.3026\n"
     ]
    }
   ],
   "source": [
    "# Better prediction lower loss\n",
    "# Y must be one hot encoded [0,1,2]\n",
    "# Predicted Y is probabilities so need to apply softmax \n",
    "\n",
    "# Manual calculation of cross entropy loss\n",
    "def manual_cross_entropy(actual,predicted):\n",
    "    loss = -np.sum(actual*np.log(predicted))\n",
    "    return loss\n",
    "\n",
    "# Actual Y\n",
    "Y = np.array([1,0,0])\n",
    "# y_pred has probabilities\n",
    "Y_pred_good = np.array([0.7,0.2,0.2])\n",
    "Y_pred_bad = np.array([0.1,0.3,0.6])\n",
    "\n",
    "l1 = manual_cross_entropy(Y,Y_pred_good)\n",
    "l2 = manual_cross_entropy(Y,Y_pred_bad)\n",
    "\n",
    "print(f'Loss 1: {l1:.4f}') # Better prediction lower loss\n",
    "print(f'Loss 2: {l2:.4f}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6056727e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss 1: 0.4170\n",
      "Loss 2: 1.8406\n",
      "Prediction 1: tensor([0])\n",
      "Prediction 2: tensor([1])\n"
     ]
    }
   ],
   "source": [
    "# Using pytorch\n",
    "# nn.CrossEntropyLoss apply softmax , so no need to apply softmax manually\n",
    "# Y must not be one hot encoded\n",
    "# Y_pred has raw scores(logits), without softmax\n",
    "\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "Y = torch.tensor([0]) # Only correct class, not one hot encoded\n",
    "Y_pred_good = torch.tensor([[2.0,1.0,0.1]])\n",
    "Y_pred_bad = torch.tensor([[0.5,2.0,0.3]])\n",
    "\n",
    "\n",
    "l1 = loss(Y_pred_good,Y)\n",
    "l2 = loss(Y_pred_bad,Y)\n",
    "\n",
    "\n",
    "print(f'Loss 1: {l1.item():.4f}') # Better prediction lower loss\n",
    "print(f'Loss 2: {l2.item():.4f}') \n",
    "\n",
    "\n",
    "_,pred1 = torch.max(Y_pred_good,1)\n",
    "_,pred2 = torch.max(Y_pred_bad,1)\n",
    "\n",
    "\n",
    "print(f'Prediction 1: {pred1}') \n",
    "print(f'Prediction 2: {pred2}') \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
