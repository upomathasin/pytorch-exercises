{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b439a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Transfer learning is a machine learning technique where a pre-trained model (trained on a large dataset and task) is reused as the starting point for a new but related task.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a8c8989",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting kagglehub\n",
      "  Downloading kagglehub-0.3.12-py3-none-any.whl.metadata (38 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\tahsi\\miniconda3\\envs\\pytorch_practice\\lib\\site-packages (from kagglehub) (25.0)\n",
      "Collecting pyyaml (from kagglehub)\n",
      "  Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting requests (from kagglehub)\n",
      "  Downloading requests-2.32.4-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting tqdm (from kagglehub)\n",
      "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests->kagglehub)\n",
      "  Downloading charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests->kagglehub)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests->kagglehub)\n",
      "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests->kagglehub)\n",
      "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\tahsi\\miniconda3\\envs\\pytorch_practice\\lib\\site-packages (from tqdm->kagglehub) (0.4.6)\n",
      "Downloading kagglehub-0.3.12-py3-none-any.whl (67 kB)\n",
      "Downloading PyYAML-6.0.2-cp39-cp39-win_amd64.whl (162 kB)\n",
      "Downloading requests-2.32.4-py3-none-any.whl (64 kB)\n",
      "Downloading charset_normalizer-3.4.2-cp39-cp39-win_amd64.whl (105 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
      "Downloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
      "Downloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: urllib3, tqdm, pyyaml, idna, charset_normalizer, certifi, requests, kagglehub\n",
      "\n",
      "   ---------------------------------------- 0/8 [urllib3]\n",
      "   ----- ---------------------------------- 1/8 [tqdm]\n",
      "   ---------- ----------------------------- 2/8 [pyyaml]\n",
      "   --------------- ------------------------ 3/8 [idna]\n",
      "   ------------------------------ --------- 6/8 [requests]\n",
      "   ----------------------------------- ---- 7/8 [kagglehub]\n",
      "   ---------------------------------------- 8/8 [kagglehub]\n",
      "\n",
      "Successfully installed certifi-2025.4.26 charset_normalizer-3.4.2 idna-3.10 kagglehub-0.3.12 pyyaml-6.0.2 requests-2.32.4 tqdm-4.67.1 urllib3-2.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "68c50df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import shutil\n",
    "import kagglehub\n",
    "from torchvision import models\n",
    "import torchvision.models as models\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split,DataLoader\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "21860a7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading from https://www.kaggle.com/api/v1/datasets/download/tawsifurrahman/covid19-radiography-database?dataset_version_number=5...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 778M/778M [03:04<00:00, 4.42MB/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\tahsi\\\\.cache\\\\kagglehub\\\\datasets\\\\tawsifurrahman\\\\covid19-radiography-database\\\\versions\\\\5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "path = kagglehub.dataset_download(\"tawsifurrahman/covid19-radiography-database\")\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f3f87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define source and destination folder\n",
    "source_root = os.path.join(path,'COVID-19_Radiography_Dataset')\n",
    "target_root = 'C:/Pytorch Practice/Data/COVID19_CLASSIFICATION'\n",
    "classes = ['COVID', 'Normal', 'Lung_Opacity', 'Viral Pneumonia']\n",
    "for cls in classes:\n",
    "  src_folder = os.path.join(source_root,cls,'images')\n",
    "  dst_folder = os.path.join(target_root,cls)\n",
    "  os.makedirs(dst_folder,exist_ok=True)\n",
    "\n",
    "  for file in os.listdir(src_folder):\n",
    "    src_file = os.path.join(src_folder,file)\n",
    "    dst_file = os.path.join(dst_folder,file)\n",
    "    if os.path.isfile(src_file):\n",
    "      shutil.copy2(src_file,dst_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cf887",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "  transforms.Resize((224, 224)),\n",
    "  transforms.ToTensor(),\n",
    "])\n",
    "dataset = datasets.ImageFolder(root='C:/Pytorch Practice/Data/COVID19_CLASSIFICATION',transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301d83b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8*len(dataset))\n",
    "val_size = len(dataset)- train_size\n",
    "\n",
    "# Split train and validation dataset\n",
    "train_dataset, val_dataset = random_split(dataset,[train_size,val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf37a2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset,batch_size=32,shuffle=True)\n",
    "val_loader = DataLoader(val_dataset,batch_size=32,shuffle=False)\n",
    "# define device and model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39642ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define model, loss function and optimizer\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features,4)  # Just modify last fully connected layer \n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr = 0.0001)\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "print('Pretrained Resnet model\\n')\n",
    "# Training and validation \n",
    "for epoch in range(num_epochs):\n",
    "  model.train()\n",
    "  running_loss = 0.0\n",
    "  correct,total = 0,0\n",
    "\n",
    "  for inputs,labels in train_loader:\n",
    "    inputs, labels = inputs.to(device),labels.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs,labels)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    running_loss+= loss.item()\n",
    "    _,pred = outputs.max(1)\n",
    "    correct +=(pred==labels).sum().item()\n",
    "    total+= labels.size(0)\n",
    "\n",
    "  train_acc = 100* correct/total\n",
    "\n",
    "  # validation\n",
    "  model.eval()\n",
    "  val_correct = 0\n",
    "  val_total = 0\n",
    "  with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "      inputs, labels = inputs.to(device),labels.to(device)\n",
    "      outputs = model(inputs)\n",
    "      _,pred = outputs.max(1)\n",
    "      val_correct +=(pred==labels).sum().item()\n",
    "      val_total+= labels.size(0)\n",
    "\n",
    "  val_acc = 100* val_correct/val_total\n",
    "\n",
    "  print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {running_loss:.4f} | Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
